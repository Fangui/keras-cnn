{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a custom CNN with 21 convolutions layers and 3,421,258 parameters.\n",
    "They are 4 blocks of 4convolutions layers, connected in a DenseNet way, \n",
    "with a transition block (the bottleneck) having a convolution \n",
    "that divided the number of filters by 2 with kernel size of 1 and a maxpooling2D.\n",
    "I also add a convolution, with a kernel_size 1 and stride 2, that is connected \n",
    "to the next block like Xception.\n",
    "\n",
    "To prevent the overfitting, there are:\n",
    "- Data augmentation\n",
    "- Batch_normalization\n",
    "- Save model with best validation accurary\n",
    "- Use global averaging instead of a dense which is sensible to overfitting\n",
    "\n",
    "There is also data augmentation in validation to improve the amount of sample in the validation set (4059 * 3), so\n",
    "the best validation accuracy should give a good accuracy in the testing set.\n",
    "\n",
    "One callback has been added to save the best validation accuray.\n",
    "\n",
    "The model reduces the vanishing gradient by the implementation of:\n",
    "- Skip connection\n",
    "- Use relu as activation function\n",
    "\n",
    "I tried to add intermediate output layer like inception model but it did not give \n",
    "better output, maybe because the neural network is quite small.\n",
    "\n",
    "The optimizer use is Adam, with a learning rate set to 1e-3, the optimizer will lower\n",
    "the learning rate when the weight started to be well trained.\n",
    "\n",
    "After 30 epochs, the model achieves 92% accuracy in the validation test.\n",
    "\n",
    "After 60 epochs, the model achieves 93.29% accuracy in the validation test.\n",
    "\n",
    "After 90 epochs, the model achieves 94.56% accuracy in the validation test.\n",
    "\n",
    "After 120 epochs, the model achieves 95.48% accuracy in the validation test.\n",
    "\n",
    "Every 30 epochs, I helped the neural network to train by loading the best validation accuracy \n",
    "in the 30 epochs previous epochs, and restarted a training session (3 times). \n",
    "\n",
    "For training from scratch, comment the load_weight in the second cell, change the learning to 1e-3, in the fit_generator\n",
    "change the value of variable nb_training to 5 and epochs to 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "input_shape = (128, 192, 3)\n",
    "\n",
    "def conv_normalization(filters, kernel_size, layer, strides = 1):\n",
    "    x = Conv2D(filters, kernel_size, activation='relu', padding='same', strides = strides, kernel_initializer='he_normal')(layer)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def cnn_model(input_shape, len_out, max_pool = True):\n",
    "    channel = 64\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv = conv_normalization(channel, 3, inputs)\n",
    "    \n",
    "    filters = channel\n",
    "    for i in range (4): # nb_block layer\n",
    "        filters = filters // 2  #transition block\n",
    "        print(filters)\n",
    "        conv = conv_normalization(filters, 1, conv) #Transition block\n",
    "        conv_prev = conv\n",
    "        conv = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "            \n",
    "        conv_inter = conv_normalization(filters, 3, conv)\n",
    "        conv_inter2 = conv_normalization(filters, 3, conv_inter)\n",
    "        conv_inter3 = conv_normalization(filters, 3, conv_inter2)\n",
    "        conv = concatenate([conv_normalization(filters, 3, conv_inter3), conv_inter, conv_inter2, \n",
    "                            conv_normalization(filters, 1, conv_prev, 2)], axis=3)\n",
    "        filters = 4 * filters\n",
    "        \n",
    "    x = GlobalAveragePooling2D()(conv)\n",
    "    outputs = Dense(len_out, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    return model, filters\n",
    "\n",
    "model, filters = cnn_model(input_shape, 10)\n",
    "model.load_weights('../input/convo-21/clement_fang_cnn21.h5')\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 1e-4),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 192, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 192, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 192, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 192, 32) 2080        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 192, 32) 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 96, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 96, 32)   9248        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 96, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 96, 32)   9248        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 96, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 96, 32)   9248        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 96, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 96, 32)   9248        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 96, 32)   1056        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 96, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 96, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 96, 128)  0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 96, 64)   8256        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 96, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 48, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 48, 64)   36928       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 48, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 48, 64)   36928       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 48, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 48, 64)   36928       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 48, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 48, 64)   36928       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 48, 64)   4160        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 48, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 48, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 48, 256)  0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 48, 128)  32896       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 48, 128)  512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 24, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 24, 128)  147584      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 24, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 24, 128)  147584      batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 24, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 24, 128)  147584      batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 24, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 24, 128)  147584      batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 24, 128)  16512       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 24, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 24, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 24, 512)  0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 24, 256)  131328      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 24, 256)  1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 12, 256)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 12, 256)   590080      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 12, 256)   1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 12, 256)   590080      batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 12, 256)   1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 12, 256)   590080      batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 12, 256)   1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 12, 256)   590080      batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 12, 256)   65792       batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 12, 256)   1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 8, 12, 256)   1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 12, 1024)  0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1024)         0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           10250       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 3,421,258\n",
      "Trainable params: 3,415,370\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36568 images belonging to 10 classes.\n",
      "Found 4059 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size = 128\n",
    "input_size = (128, 192)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "            rescale=1. / 255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            validation_split=0.1,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "            directory=\"../input/training-ships/ships_train2/ships_train\",\n",
    "            target_size=input_size,\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=batch_size,\n",
    "            class_mode=\"categorical\",\n",
    "            subset = \"training\",\n",
    "            shuffle=True)\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "            directory=\"../input/training-ships/ships_train2/ships_train\",\n",
    "            target_size=input_size,\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=batch_size,\n",
    "            class_mode=\"categorical\",\n",
    "            subset = \"validation\",\n",
    "            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "def compute_score(res, Y_test):\n",
    "    s = 0\n",
    "    for i in range (len(res)):\n",
    "        if res[i] == Y_test[i]:\n",
    "            s += 1\n",
    "    return s / (len(res))\n",
    "\n",
    "ships = np.load('../input/reco-nav-2/ships_test.npz')\n",
    "X_test = ships['X']\n",
    "Y_test = ships['Y']\n",
    "Y_cat = np_utils.to_categorical(Y_test)\n",
    "del ships\n",
    "\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "nb_training = 0  # 5 for long session\n",
    "epochs = 40\n",
    "\n",
    "weight_path = 'network.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(weight_path, monitor='val_acc', save_best_only=True, save_weights_only=True, verbose = 1)\n",
    "\n",
    "for i in range (nb_training):\n",
    "    if i == 2:\n",
    "        model.compile(optimizer = Adam(lr = 1e-4), # change the lr from 1e-3 to 1e-4\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    elif i == 3:\n",
    "        model.compile(optimizer = Adam(lr = 1e-5), # change the lr from 1e-4 to 1e-5\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit_generator(\n",
    "                train_generator,\n",
    "                validation_data = val_generator,\n",
    "                validation_steps=(4059 // batch_size) * 3,\n",
    "                callbacks=[model_checkpoint],\n",
    "                steps_per_epoch = 36568 // batch_size,\n",
    "                epochs=epochs)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "        \n",
    "    model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nb_training:\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.9560439560439561\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>cru</th>\n",
       "      <th>des</th>\n",
       "      <th>coa</th>\n",
       "      <th>sma</th>\n",
       "      <th>met</th>\n",
       "      <th>cv</th>\n",
       "      <th>cor</th>\n",
       "      <th>sub</th>\n",
       "      <th>tug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>containership</th>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cruiser</th>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>destroyer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coastguard</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smallfish</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methanier</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corvette</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submarine</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tug</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               con  cru  des  coa  sma  met  cv  cor  sub  tug\n",
       "containership  275    1    0    0    0    0   0    0    0    0\n",
       "cruiser          0  258    0    0    0    0   1    0    0    0\n",
       "destroyer        0    0  273    2    0    0   3    6    0    0\n",
       "coastguard       0    1    2  136    3    0   0    2    1    4\n",
       "smallfish        1    0    0    2  127    0   0    0    0    0\n",
       "methanier        2    0    0    0    3  158   0    1    0    0\n",
       "cv               0    1    3    0    1    0  80    1    0    0\n",
       "corvette         0    0   15    2    2    0   5  113    1    0\n",
       "submarine        0    0    0    0    1    0   1    1   97    3\n",
       "tug              0    0    1    2    1    0   0    0    0  136"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model.save(\"clement_fang_21cnn.h5\")\n",
    "res = model.predict(X_test).argmax(axis=1)\n",
    "confu = confusion_matrix(Y_cat.argmax(axis=1), res)\n",
    "print (\"score: \", compute_score(res, Y_test))\n",
    "types = ['containership', 'cruiser', 'destroyer','coastguard', 'smallfish', 'methanier', 'cv', 'corvette', 'submarine', 'tug']\n",
    "pd.DataFrame({types[i][:3]:confu[:,i] for i in range(len(types))}, index=types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"network2.hdf5\">link</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
